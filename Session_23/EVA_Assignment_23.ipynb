{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EVA_Assignment_23.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w8Lrn5v45KZZ",
        "colab": {}
      },
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "# from renderFace import renderFace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LjhO3ay8oL1N",
        "colab": {}
      },
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive/')\n",
        " main_path = '/content/drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KCV__vGAhwLp",
        "colab": {}
      },
      "source": [
        "main_path = '/content/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MTHwRlgnh0Ds"
      },
      "source": [
        "# FaceBlendCommon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gkuDvDAZhewO",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Returns 8 points on the boundary of a rectangle\n",
        "def getEightBoundaryPoints(h, w):\n",
        "  boundaryPts = []\n",
        "  boundaryPts.append((0,0))\n",
        "  boundaryPts.append((w/2, 0))\n",
        "  boundaryPts.append((w-1,0))\n",
        "  boundaryPts.append((w-1, h/2))\n",
        "  boundaryPts.append((w-1, h-1))\n",
        "  boundaryPts.append((w/2, h-1))\n",
        "  boundaryPts.append((0, h-1))\n",
        "  boundaryPts.append((0, h/2))\n",
        "  return np.array(boundaryPts, dtype=np.float)\n",
        "\n",
        "\n",
        "# Constrains points to be inside boundary\n",
        "def constrainPoint(p, w, h):\n",
        "  p = (min(max(p[0], 0), w - 1), min(max(p[1], 0), h - 1))\n",
        "  return p\n",
        "\n",
        "# convert Dlib shape detector object to list of tuples\n",
        "def dlibLandmarksToPoints(shape):\n",
        "  points = []\n",
        "  for p in shape.parts():\n",
        "    pt = (p.x, p.y)\n",
        "    points.append(pt)\n",
        "  return points\n",
        "\n",
        "# Compute similarity transform given two sets of two points.\n",
        "# OpenCV requires 3 pairs of corresponding points.\n",
        "# We are faking the third one.\n",
        "def similarityTransform(inPoints, outPoints):\n",
        "  s60 = math.sin(60*math.pi/180)\n",
        "  c60 = math.cos(60*math.pi/180)\n",
        "\n",
        "  inPts = np.copy(inPoints).tolist()\n",
        "  outPts = np.copy(outPoints).tolist()\n",
        "\n",
        "  # The third point is calculated so that the three points make an equilateral triangle\n",
        "  xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0]\n",
        "  yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1]\n",
        "\n",
        "  inPts.append([np.int(xin), np.int(yin)])\n",
        "\n",
        "  xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0]\n",
        "  yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1]\n",
        "\n",
        "  outPts.append([np.int(xout), np.int(yout)])\n",
        "\n",
        "  # Now we can use estimateRigidTransform for calculating the similarity transform.\n",
        "  tform = cv2.estimateAffinePartial2D(np.array([inPts]), np.array([outPts]))\n",
        "  return tform[0]\n",
        "    \n",
        "# Normalizes a facial image to a standard size given by outSize.\n",
        "# Normalization is done based on Dlib's landmark points passed as pointsIn\n",
        "# After normalization, left corner of the left eye is at (0.3 * w, h/3 )\n",
        "# and right corner of the right eye is at ( 0.7 * w, h / 3) where w and h\n",
        "# are the width and height of outSize.\n",
        "def normalizeImagesAndLandmarks(outSize, imIn, pointsIn):\n",
        "  h, w = outSize\n",
        "#   print(f\"(HxW)={outSize} not matching with video frames shape={imIn.shape}\")\n",
        "  # Corners of the eye in input image\n",
        "  if len(pointsIn) == 68:\n",
        "    eyecornerSrc = [pointsIn[36], pointsIn[45]]\n",
        "  elif len(pointsIn) == 5:\n",
        "    eyecornerSrc = [pointsIn[2], pointsIn[0]]\n",
        "  else:\n",
        "    print(f\"(H x W)={outSize} not matching with video frames shape={imIn.shape}\")\n",
        "\n",
        "  # Corners of the eye in normalized image\n",
        "  eyecornerDst = [(np.int(0.3 * w), np.int(h/3)),\n",
        "                  (np.int(0.7 * w), np.int(h/3))]\n",
        "\n",
        "  # Calculate similarity transform\n",
        "  tform = similarityTransform(eyecornerSrc, eyecornerDst)\n",
        "  imOut = np.zeros(imIn.shape, dtype=imIn.dtype)\n",
        "\n",
        "  # Apply similarity transform to input image\n",
        "  imOut = cv2.warpAffine(imIn, tform, (w, h))\n",
        "\n",
        "  # reshape pointsIn from numLandmarks x 2 to numLandmarks x 1 x 2\n",
        "  points2 = np.reshape(pointsIn, (pointsIn.shape[0], 1, pointsIn.shape[1]))\n",
        "\n",
        "  # Apply similarity transform to landmarks\n",
        "  pointsOut = cv2.transform(points2, tform)\n",
        "\n",
        "  # reshape pointsOut to numLandmarks x 2\n",
        "  pointsOut = np.reshape(pointsOut, (pointsIn.shape[0], pointsIn.shape[1]))\n",
        "\n",
        "  return imOut, pointsOut\n",
        "\n",
        "# find the point closest to an array of points\n",
        "# pointsArray is a Nx2 and point is 1x2 ndarray\n",
        "def findIndex(pointsArray, point):\n",
        "  dist = np.linalg.norm(pointsArray-point, axis=1)\n",
        "  minIndex = np.argmin(dist)\n",
        "  return minIndex\n",
        "\n",
        "\n",
        "# Check if a point is inside a rectangle\n",
        "def rectContains(rect, point):\n",
        "  if point[0] < rect[0]:\n",
        "    return False\n",
        "  elif point[1] < rect[1]:\n",
        "    return False\n",
        "  elif point[0] > rect[2]:\n",
        "    return False\n",
        "  elif point[1] > rect[3]:\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "\n",
        "# Calculate Delaunay triangles for set of points\n",
        "# Returns the vector of indices of 3 points for each triangle\n",
        "def calculateDelaunayTriangles(rect, points):\n",
        "\n",
        "  # Create an instance of Subdiv2D\n",
        "  subdiv = cv2.Subdiv2D(rect)\n",
        "\n",
        "  # Insert points into subdiv\n",
        "  for p in points:\n",
        "    subdiv.insert((p[0], p[1]))\n",
        "\n",
        "  # Get Delaunay triangulation\n",
        "  triangleList = subdiv.getTriangleList()\n",
        "\n",
        "  # Find the indices of triangles in the points array\n",
        "  delaunayTri = []\n",
        "\n",
        "  for t in triangleList:\n",
        "    # The triangle returned by getTriangleList is\n",
        "    # a list of 6 coordinates of the 3 points in\n",
        "    # x1, y1, x2, y2, x3, y3 format.\n",
        "    # Store triangle as a list of three points\n",
        "    pt = []\n",
        "    pt.append((t[0], t[1]))\n",
        "    pt.append((t[2], t[3]))\n",
        "    pt.append((t[4], t[5]))\n",
        "\n",
        "    pt1 = (t[0], t[1])\n",
        "    pt2 = (t[2], t[3])\n",
        "    pt3 = (t[4], t[5])\n",
        "\n",
        "    if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n",
        "      # Variable to store a triangle as indices from list of points\n",
        "      ind = []\n",
        "      # Find the index of each vertex in the points list\n",
        "      for j in range(0, 3):\n",
        "        for k in range(0, len(points)):\n",
        "          if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n",
        "            ind.append(k)\n",
        "        # Store triangulation as a list of indices\n",
        "      if len(ind) == 3:\n",
        "        delaunayTri.append((ind[0], ind[1], ind[2]))\n",
        "\n",
        "  return delaunayTri\n",
        "\n",
        "# Apply affine transform calculated using srcTri and dstTri to src and\n",
        "# output an image of size.\n",
        "def applyAffineTransform(src, srcTri, dstTri, size):\n",
        "\n",
        "  # Given a pair of triangles, find the affine transform.\n",
        "  warpMat = cv2.getAffineTransform(np.float32(srcTri), np.float32(dstTri))\n",
        "\n",
        "  # Apply the Affine Transform just found to the src image\n",
        "  dst = cv2.warpAffine(src, warpMat, (size[0], size[1]), None,\n",
        "             flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "  return dst\n",
        "\n",
        "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
        "def warpTriangle(img1, img2, t1, t2):\n",
        "  # Find bounding rectangle for each triangle\n",
        "  r1 = cv2.boundingRect(np.float32([t1]))\n",
        "  r2 = cv2.boundingRect(np.float32([t2]))\n",
        "\n",
        "  # Offset points by left top corner of the respective rectangles\n",
        "  t1Rect = []\n",
        "  t2Rect = []\n",
        "  t2RectInt = []\n",
        "\n",
        "  for i in range(0, 3):\n",
        "    t1Rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))\n",
        "    t2Rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
        "    t2RectInt.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
        "\n",
        "  # Get mask by filling triangle\n",
        "  mask = np.zeros((r2[3], r2[2], 3), dtype=np.float32)\n",
        "  cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0)\n",
        "\n",
        "  # Apply warpImage to small rectangular patches\n",
        "  img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
        "\n",
        "  size = (r2[2], r2[3])\n",
        "\n",
        "  img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n",
        "\n",
        "  img2Rect = img2Rect * mask\n",
        "\n",
        "  # Copy triangular region of the rectangular patch to the output image\n",
        "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ((1.0, 1.0, 1.0) - mask)\n",
        "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect\n",
        "\n",
        "# detect facial landmarks in image\n",
        "def getLandmarks(faceDetector, landmarkDetector, im, FACE_DOWNSAMPLE_RATIO = 1):\n",
        "  points = []\n",
        "  imSmall = cv2.resize(im,None,\n",
        "                       fx=1.0/FACE_DOWNSAMPLE_RATIO,\n",
        "                       fy=1.0/FACE_DOWNSAMPLE_RATIO,\n",
        "                       interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "  faceRects = faceDetector(imSmall, 0)\n",
        "\n",
        "  if len(faceRects) > 0:\n",
        "    maxArea = 0\n",
        "    maxRect = None\n",
        "    # TODO: test on images with multiple faces\n",
        "    for face in faceRects:\n",
        "      if face.area() > maxArea:\n",
        "        maxArea = face.area()\n",
        "        maxRect = [face.left(),\n",
        "                   face.top(),\n",
        "                   face.right(),\n",
        "                   face.bottom()\n",
        "                  ]\n",
        "\n",
        "    rect = dlib.rectangle(*maxRect)\n",
        "    scaledRect = dlib.rectangle(int(rect.left()*FACE_DOWNSAMPLE_RATIO),\n",
        "                             int(rect.top()*FACE_DOWNSAMPLE_RATIO),\n",
        "                             int(rect.right()*FACE_DOWNSAMPLE_RATIO),\n",
        "                             int(rect.bottom()*FACE_DOWNSAMPLE_RATIO))\n",
        "\n",
        "    landmarks = landmarkDetector(im, scaledRect)\n",
        "    points = dlibLandmarksToPoints(landmarks)\n",
        "  return points\n",
        "\n",
        "# Warps an image in a piecewise affine manner.\n",
        "# The warp is defined by the movement of landmark points specified by pointsIn\n",
        "# to a new location specified by pointsOut. The triangulation beween points is specified\n",
        "# by their indices in delaunayTri.\n",
        "def warpImage(imIn, pointsIn, pointsOut, delaunayTri):\n",
        "  h, w, ch = imIn.shape\n",
        "  # Output image\n",
        "  imOut = np.zeros(imIn.shape, dtype=imIn.dtype)\n",
        "\n",
        "  # Warp each input triangle to output triangle.\n",
        "  # The triangulation is specified by delaunayTri\n",
        "  for j in range(0, len(delaunayTri)):\n",
        "    # Input and output points corresponding to jth triangle\n",
        "    tin = []\n",
        "    tout = []\n",
        "\n",
        "    for k in range(0, 3):\n",
        "      # Extract a vertex of input triangle\n",
        "      pIn = pointsIn[delaunayTri[j][k]]\n",
        "      # Make sure the vertex is inside the image.\n",
        "      pIn = constrainPoint(pIn, w, h)\n",
        "\n",
        "      # Extract a vertex of the output triangle\n",
        "      pOut = pointsOut[delaunayTri[j][k]]\n",
        "      # Make sure the vertex is inside the image.\n",
        "      pOut = constrainPoint(pOut, w, h)\n",
        "\n",
        "      # Push the input vertex into input triangle\n",
        "      tin.append(pIn)\n",
        "      # Push the output vertex into output triangle\n",
        "      tout.append(pOut)\n",
        "\n",
        "    # Warp pixels inside input triangle to output triangle.\n",
        "    warpTriangle(imIn, imOut, tin, tout)\n",
        "  return imOut\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0e7YFutBiDZg"
      },
      "source": [
        "### RenderFace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-zY7Wzbjhepi",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def drawPolyline(im, landmarks, start, end, isClosed=False):\n",
        "  points = []\n",
        "  for i in range(start, end+1):\n",
        "    point = [landmarks.part(i).x, landmarks.part(i).y]\n",
        "    points.append(point)\n",
        "\n",
        "  points = np.array(points, dtype=np.int32)\n",
        "  cv2.polylines(im, [points], isClosed, (255, 200, 0), thickness=2, lineType=cv2.LINE_8)\n",
        "\n",
        "# Use this function for 70-points facial landmark detector model\n",
        "def renderFace(im, landmarks):\n",
        "    assert(landmarks.num_parts == 68)\n",
        "    drawPolyline(im, landmarks, 0, 16)           # Jaw line\n",
        "    drawPolyline(im, landmarks, 17, 21)          # Left eyebrow\n",
        "    drawPolyline(im, landmarks, 22, 26)          # Right eyebrow\n",
        "    drawPolyline(im, landmarks, 27, 30)          # Nose bridge\n",
        "    drawPolyline(im, landmarks, 30, 35, True)    # Lower nose\n",
        "    drawPolyline(im, landmarks, 36, 41, True)    # Left eye\n",
        "    drawPolyline(im, landmarks, 42, 47, True)    # Right Eye\n",
        "    drawPolyline(im, landmarks, 48, 59, True)    # Outer lip\n",
        "    drawPolyline(im, landmarks, 60, 67, True)    # Inner lip\n",
        "\n",
        "# Use this function for any model other than\n",
        "# 70 points facial_landmark detector model\n",
        "def renderFace2(im, landmarks, color=(0, 255, 0), radius=3):\n",
        "  for p in landmarks.parts():\n",
        "    cv2.circle(im, (p.x, p.y), radius, color, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pteLz5BliT2l"
      },
      "source": [
        "### NormalizeImagesAndLandmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBVJsX58hee8",
        "colab": {}
      },
      "source": [
        "def normalizeImagesAndLandmarks(outSize, imIn, pointsIn):\n",
        "  h, w = outSize\n",
        "\n",
        "  # Corners of the eye in input image\n",
        "  if len(pointsIn) == 68:\n",
        "    eyecornerSrc = [pointsIn[36], pointsIn[45]]\n",
        "  elif len(pointsIn) == 5:\n",
        "    eyecornerSrc = [pointsIn[2], pointsIn[0]]\n",
        "\n",
        "  # Corners of the eye in normalized image\n",
        "  eyecornerDst = [(np.int(0.3 * w), np.int(h/3)),\n",
        "                  (np.int(0.7 * w), np.int(h/3))]\n",
        "\n",
        "  # Calculate similarity transform\n",
        "  tform = similarityTransform(eyecornerSrc, eyecornerDst)\n",
        "  imOut = np.zeros(imIn.shape, dtype=imIn.dtype)\n",
        "\n",
        "  # Apply similarity transform to input image\n",
        "  imOut = cv2.warpAffine(imIn, tform, (w, h))\n",
        "\n",
        "  # reshape pointsIn from numLandmarks x 2 to numLandmarks x 1 x 2\n",
        "  points2 = np.reshape(pointsIn, \n",
        "                      (pointsIn.shape[0], 1, pointsIn.shape[1]))\n",
        "\n",
        "  # Apply similarity transform to landmarks\n",
        "  pointsOut = cv2.transform(points2, tform)\n",
        "\n",
        "  # reshape pointsOut to numLandmarks x 2\n",
        "  pointsOut = np.reshape(pointsOut, \n",
        "                          (pointsIn.shape[0], pointsIn.shape[1]))\n",
        "\n",
        "  return imOut, pointsOut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4MLFbLQLidA6"
      },
      "source": [
        "### LandmarkDetector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9srQxRKviBui",
        "colab": {}
      },
      "source": [
        "matplotlib.rcParams['figure.figsize'] = (6.0,6.0)\n",
        "matplotlib.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "def writeLandmarksToFile(landmarks, landmarksFileName):\n",
        "  with open(landmarksFileName, 'w') as f:\n",
        "    for p in landmarks.parts():\n",
        "      f.write(\"%s %s\\n\" %(int(p.x),int(p.y)))\n",
        "  f.close()\n",
        "\n",
        "PREDICTOR_68_PATH = main_path + \"shape_68_face_landmarks.dat\"\n",
        "PREDICTOR_5_PATH = main_path + \"shape_5_face_landmarks.dat\"\n",
        "\n",
        "# import faceBlendCommon as fbc\n",
        "DATA_PATH = \"./\"\n",
        "MODEL_PATH = \"./\"\n",
        "# from dataPath import DATA_PATH\n",
        "# from dataPath import MODEL_PATH\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "\n",
        "# Get the face detector\n",
        "faceDetector = dlib.get_frontal_face_detector()\n",
        "# The landmark detector is implemented in the shape_predictor class\n",
        "landmarkDetector_5_point = dlib.shape_predictor(PREDICTOR_5_PATH)\n",
        "landmarkDetector_68_point = dlib.shape_predictor(PREDICTOR_68_PATH)\n",
        "\n",
        "def drow_circle_points(img, pointsOut):\n",
        "    imgs  = np.copy(img)\n",
        "    for (x, y) in pointsOut:\n",
        "        imgs = cv2.circle(imgs, (x, y), 2, (0, 255, 0), -1)\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def get_5_pt_detector(frame, fd= faceDetector, lmd=landmarkDetector_5_point):\n",
        "    # faceDetector, landmarkDetector, im,\n",
        "    points_5 = getLandmarks(landmarkDetector= lmd, faceDetector=fd, im=frame)\n",
        "    return np.array(points_5)\n",
        "\n",
        "\n",
        "def get_68_pt_detector(frame, fd= faceDetector, lmd=landmarkDetector_68_point):\n",
        "    points_68 = getLandmarks(landmarkDetector= lmd, faceDetector=fd, im=frame)\n",
        "    return np.array(points_68)\n",
        "\n",
        "\n",
        "def img_and_pont_circle_norm(points, h=480, w=220):\n",
        "    imNorm, points = normalizeImagesAndLandmarks((h, w), np.float32(frame)/255.0, points)\n",
        "    imNorm = np.uint8(imNorm*255)        \n",
        "    img_with_point = drow_circle_points(imNorm, points)\n",
        "    return imNorm, img_with_point"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3iA9l_KFVgC"
      },
      "source": [
        "#### Optical Flow(Stabilization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zr4VDTeKRIr_",
        "colab": {}
      },
      "source": [
        "import cv2, dlib\n",
        "import numpy as np\n",
        "import math, sys\n",
        "# from dataPath import DATA_PATH\n",
        "# from dataPath import MODEL_PATH\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (6.0,6.0)\n",
        "matplotlib.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "PREDICTOR_PATH = main_path+\"shape_68_face_landmarks.dat\"\n",
        "RESIZE_HEIGHT = 480\n",
        "NUM_FRAMES_FOR_FPS = 100\n",
        "SKIP_FRAMES = 1\n",
        "\n",
        "# Function to calculate the intereye distance.\n",
        "def interEyeDistance(predict):\n",
        "  leftEyeLeftCorner = (predict[36].x, predict[36].y)\n",
        "  rightEyeRightCorner = (predict[45].x, predict[45].y)\n",
        "  distance = cv2.norm(np.array(rightEyeRightCorner) - np.array(leftEyeLeftCorner))\n",
        "  distance = int(distance)\n",
        "  return distance\n",
        "\n",
        "winName = \"Stabilized facial landmark detector\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AdOF31GcFZCy",
        "colab": {}
      },
      "source": [
        "videoFileName = main_path+ \"New_Input_1.avi\"\n",
        "\n",
        "# Initializing video capture object.\n",
        "# cap = cv2.VideoCapture('./Input_Stabilize.avi')\n",
        "cap = cv2.VideoCapture(videoFileName)\n",
        "\n",
        "\n",
        "if(cap.isOpened()==False):\n",
        "  print(\"Unable to load video\")\n",
        "\n",
        "\n",
        "winSize = 101\n",
        "maxLevel = 10\n",
        "fps = 30.0\n",
        "# Grab a frame\n",
        "ret,imPrev = cap.read()\n",
        "# Finding the size of the image.\n",
        "size = imPrev.shape[0:1]\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "# PREDICTOR_PATH = PREDICTOR_5\n",
        "landmarkDetector = dlib.shape_predictor(main_path+'shape_68_face_landmarks.dat')\n",
        "# Initializing the parameters\n",
        "points=[]\n",
        "pointsPrev=[]\n",
        "pointsDetectedCur=[]\n",
        "pointsDetectedPrev=[]\n",
        "\n",
        "eyeDistanceNotCalculated = True\n",
        "eyeDistance = 0\n",
        "isFirstFrame = True\n",
        "# Initial value, actual value calculated after 100 frames\n",
        "fps = 10\n",
        "showStabilized = False\n",
        "count =0  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PTuAcJSvFdiM",
        "colab": {}
      },
      "source": [
        "h = 600\n",
        "w = 400\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    print(\"cap is opened\")\n",
        "    if (count==0):\n",
        "        t = cv2.getTickCount()\n",
        "\n",
        "    # Grab a frame\n",
        "    ret,im = cap.read()\n",
        "    #print(\"ret is\",ret)\n",
        "    #print(\"im is\",im)\n",
        "#     cam = np.copy(im)\n",
        "    if ret==True:\n",
        "        points = get_68_pt_detector(frame=im)\n",
        "        if len(points)==5 or len(points)==68:\n",
        "            imNorm, points = normalizeImagesAndLandmarks((h, w), np.float32(im)/255.0, points)\n",
        "            imNorm = np.uint8(imNorm*255)\n",
        "            kk = drow_circle_points(imNorm, points)\n",
        "            cam = np.copy(im)\n",
        "            im = np.copy(imNorm)\n",
        "\n",
        "    imDlib = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    # COnverting to grayscale\n",
        "    imGray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    height = im.shape[0]\n",
        "    IMAGE_RESIZE = float(height)/RESIZE_HEIGHT\n",
        "    # Resize image for faster face detection\n",
        "    imSmall = cv2.resize(im, None, fx=1.0/IMAGE_RESIZE, fy=1.0/IMAGE_RESIZE,interpolation = cv2.INTER_LINEAR)\n",
        "    imSmallDlib = cv2.cvtColor(imSmall, cv2.COLOR_BGR2RGB)\n",
        "    # Skipping the frames for faster processing\n",
        "    if (count % SKIP_FRAMES == 0):\n",
        "        faces = detector(imSmallDlib,0)\n",
        "\n",
        "    # If no face was detected\n",
        "    if len(faces)==0:\n",
        "        print(\"No face detected\")\n",
        "\n",
        "    # If faces are detected, iterate through each image and detect landmark points\n",
        "    else:\n",
        "        for i in range(0,len(faces)):\n",
        "#       print(\"face detected\")\n",
        "            # Face detector was found over a smaller image.\n",
        "            # So, we scale face rectangle to correct size.\n",
        "            newRect = dlib.rectangle(int(faces[i].left() * IMAGE_RESIZE),\n",
        "                int(faces[i].top() * IMAGE_RESIZE),\n",
        "                int(faces[i].right() * IMAGE_RESIZE),\n",
        "                int(faces[i].bottom() * IMAGE_RESIZE))\n",
        "\n",
        "            # Detect landmarks in current frame\n",
        "            landmarks = landmarkDetector(imDlib, newRect).parts()\n",
        "\n",
        "            # Handling the first frame of video differently,for the first frame copy the current frame points\n",
        "\n",
        "            if (isFirstFrame==True):\n",
        "                pointsPrev=[]\n",
        "                pointsDetectedPrev = []\n",
        "                [pointsPrev.append((p.x, p.y)) for p in landmarks]\n",
        "                [pointsDetectedPrev.append((p.x, p.y)) for p in landmarks]\n",
        "\n",
        "            # If not the first frame, copy points from previous frame.\n",
        "            else:\n",
        "                pointsPrev=[]\n",
        "                pointsDetectedPrev = []\n",
        "                pointsPrev = points\n",
        "                pointsDetectedPrev = pointsDetectedCur\n",
        "\n",
        "            # pointsDetectedCur stores results returned by the facial landmark detector\n",
        "            # points stores the stabilized landmark points\n",
        "            points = []\n",
        "            pointsDetectedCur = []\n",
        "            [points.append((p.x, p.y)) for p in landmarks]\n",
        "            [pointsDetectedCur.append((p.x, p.y)) for p in landmarks]\n",
        "\n",
        "            # Convert to numpy float array\n",
        "            pointsArr = np.array(points,np.float32)\n",
        "            pointsPrevArr = np.array(pointsPrev,np.float32)\n",
        "\n",
        "            # If eye distance is not calculated before\n",
        "            if eyeDistanceNotCalculated:\n",
        "                eyeDistance = interEyeDistance(landmarks)\n",
        "#         print(eyeDistance)\n",
        "                eyeDistanceNotCalculated = False\n",
        "\n",
        "            if eyeDistance > 100:\n",
        "                    dotRadius = 3\n",
        "            else:\n",
        "                dotRadius = 2\n",
        "\n",
        "#       print(eyeDistance)\n",
        "            sigma = eyeDistance * eyeDistance / 400\n",
        "            s = 2*int(eyeDistance/4)+1\n",
        "\n",
        "            #  Set up optical flow params\n",
        "            lk_params = dict(winSize  = (s, s), maxLevel = 5, criteria = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 20, 0.03))\n",
        "            # Python Bug. Calculating pyramids and then calculating optical flow results in an error. So directly images are used.\n",
        "#       ret, imGrayPrev= cv2.buildOpticalFlowPyramid(imGray, (winSize,winSize), maxLevel)\n",
        "#       print(imDlib.shape,imGray.shape)\n",
        "            pointsArr,status, err = cv2.calcOpticalFlowPyrLK(im,imDlib,pointsPrevArr,pointsArr,**lk_params)\n",
        "\n",
        "\n",
        "            # Converting to float\n",
        "            pointsArrFloat = np.array(pointsArr,np.float32)\n",
        "\n",
        "            # Converting back to list\n",
        "            points = pointsArrFloat.tolist()\n",
        "\n",
        "            # Final landmark points are a weighted average of\n",
        "            # detected landmarks and tracked landmarks\n",
        "            for k in range(0,len(landmarks)):\n",
        "                d = cv2.norm(np.array(pointsDetectedPrev[k]) - np.array(pointsDetectedCur[k]))\n",
        "                alpha = math.exp(-d*d/sigma)\n",
        "                points[k] = (1 - alpha) * np.array(pointsDetectedCur[k]) + alpha * np.array(points[k])\n",
        "\n",
        "            # Drawing over the stabilized landmark points\n",
        "            if showStabilized is True:\n",
        "                for p in points:\n",
        "                    cv2.circle(im,(int(p[0]),int(p[1])),dotRadius, (255,0,0),-1)\n",
        "            else:\n",
        "                for p in pointsDetectedCur:\n",
        "                    cv2.circle(im,(int(p[0]),int(p[1])),dotRadius, (0,0,255),-1)\n",
        "\n",
        "            isFirstFrame = False\n",
        "            count = count+1\n",
        "\n",
        "            # Calculating the fps value\n",
        "            if ( count == NUM_FRAMES_FOR_FPS):\n",
        "                t = (cv2.getTickCount()-t)/cv2.getTickFrequency()\n",
        "                fps = NUM_FRAMES_FOR_FPS/t\n",
        "                count = 0\n",
        "                isFirstFrame = True\n",
        "\n",
        "            # Display the landmarks points\n",
        "            cv2.putText(im, \"{:.1f}-fps Stabilization\".format(fps), (50, size[0]-50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 0, 255), 3,cv2.LINE_AA)\n",
        "            cv2.putText(kk, \"Without Stabilization\", (50, size[0]-50), cv2.FONT_HERSHEY_COMPLEX, 0.9, (0, 255, 0), 3,cv2.LINE_AA)\n",
        "            cv2.putText(cam, \"   Original\", (50, size[0]-50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (255, 255, 255), 3,cv2.LINE_AA)\n",
        "        #   cv2.imshow(winName, im)\n",
        "            cam = cv2.resize(cam, (400,600))\n",
        "#             print(cam.shape)\n",
        "            im = np.concatenate([cam, kk,im], axis=1)\n",
        "            final_out = cv2.resize(im, (640, 480))\n",
        "            #print(\"final out is\",final_out)\n",
        "            from google.colab.patches import cv2_imshow\n",
        "            cv2_imshow(final_out)\n",
        "            out.write(final_out)\n",
        "        #   frame = cv2.flip(frame,0)\n",
        "        # write the flipped frame\n",
        "            # if frame.shape == (480, 640, 3) and final_out.shape == (480, 640, 3):\n",
        "            # \tout.write(final_out)\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                showStabilized = not showStabilized\n",
        "            imPrev = im\n",
        "            imGrayPrev = imGray\n",
        "            # Use spacebar to toggle between Stabilized and Unstabilized version.\n",
        "\n",
        "            # Stop the program.\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
        "        break\n",
        "            # Getting ready for next frame\n",
        "            \n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllwindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}